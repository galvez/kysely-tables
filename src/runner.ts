import minimist, { ParsedArgs } from 'minimist'
import { log, confirm, isCancel } from '@clack/prompts'
import pc from 'picocolors'
import { Kysely, KyselyConfig, CompiledQuery } from 'kysely'
import { performance as perf } from 'node:perf_hooks'
import { existsSync, readFileSync, writeFileSync } from 'node:fs'
import { join, parse } from 'node:path'
import {
  createSQLSchemaFromSource,
  createSQLSchemaResetFromSource,
  createSQLSchemaRevision,
  PostgresDialect,
  SqliteDialect,
} from './index'

const start = perf.now()

export function createDatabase<Database>(config: KyselyConfig) {
  const argv = minimist(process.argv.slice(1))

  const database = new Kysely<Database>(config)

  if (argv.create) {
    createSchema<Database>(argv, database)
  }

  if (argv.reset) {
    resetSchema<Database>(argv, database)
  }

  if (argv.revision) {
    createSchemaRevision<Database>(argv, database)
  }

  return database
}

async function createSchema<Database>(
  argv: ParsedArgs,
  database: Kysely<Database>,
  reset?: boolean
) {
  const { source, sourceDir, sourceFileName, sourceBaseFileName } = readSource(
    argv._[0],
  )

  const snapshotSchemaFileName = `${sourceBaseFileName}.snapshot.ts`
  const snapshotSchemaFilePath = join(sourceDir, snapshotSchemaFileName)
  if (!reset && existsSync(snapshotSchemaFilePath)) {
    console.warn(
      pc.yellow(
        `${pc.red('✖')} ${pc.cyan(
          snapshotSchemaFileName,
        )} exists, did you mean to --reset?`,
      ),
    )
    process.exit(1)
  }
  writeFileSync(snapshotSchemaFilePath, (
    '// This file was autogenerated by kysely-tables as\n' +
    '// a means of diffing against local changes in the main file\n' +
    '// for automatically generating schema revisions (migrations)\n\n' +
    source
  ))
  log.info(timed(`${pc.cyan(snapshotSchemaFileName)} written`, perf.now()))

  const generatedSchema = createSQLSchemaFromSource({
    source,
    fileName: sourceFileName,
    dialect: SqliteDialect,
  })

  const generatedSchemaFileName = `${sourceBaseFileName}.sql`
  const generatedSchemaFilePath = join(sourceDir, generatedSchemaFileName)
  writeFileSync(generatedSchemaFilePath, generatedSchema.join('\n\n'))
  log.info(timed(`${pc.cyan(generatedSchemaFileName)} written`))

  const start = perf.now()
  await database.transaction().execute(async (trx) => {
    for (const tableSchema of generatedSchema) {
      const query = CompiledQuery.raw(tableSchema)
      await trx.executeQuery(query)
    }
  })
  log.info(timed(`Database updated`, start))
  console.log()
}

async function resetSchema<Database>(
  argv: ParsedArgs,
  database: Kysely<Database>,
) {
  const { source, sourceFileName } = readSource(argv._[0])

  await database.transaction().execute(async (trx) => {
    for (const tableSchemaReset of createSQLSchemaResetFromSource({
      source,
      fileName: sourceFileName,
      dialect: SqliteDialect,
    })) {
      const query = CompiledQuery.raw(tableSchemaReset)
      await trx.executeQuery(query)
    }
  })

  await createSchema(argv, database, true)
}

async function createSchemaRevision<Database>(
  argv: ParsedArgs,
  database: Kysely<Database>,
) {
  const { source, sourceDir, sourceFileName, sourceBaseFileName } = readSource(
    argv._[0],
  )
  const snapshotFileName = `${sourceBaseFileName}.snapshot.ts`
  const snapshotFilePath = join(sourceDir, snapshotFileName)
  const snapshotSource = readFileSync(snapshotFilePath, 'utf8')
  const revision = createSQLSchemaRevision({
    source,
    snapshotSource,
    snapshotFileName,
    fileName: sourceFileName,
    dialect: SqliteDialect,
  })

  if (!revision.length) {
    log.warn(`No changes detected.`)
    process.exit()
  }

  for (const rev of revision) {
    log.info(rev)
  }

  if (argv.apply) {
    log.success(timed(`Database updated`, perf.now()))
  } else {
    const apply = await confirm({
      message: 'Apply schema revision?'
    })    
    if (apply && !isCancel(isCancel)) {
      // success(`${pc.green('✔')} database updated`, perf.now())
      log.success(timed(`Database updated`, perf.now()))
    }
  }

  // await database.transaction().execute(async (trx) => {
  //   for (const stmt of revision) {
  //     const query = CompiledQuery.raw(stmt)
  //     await trx.executeQuery(query)
  //   }
  // })
}

function readSource(sourceFilePath: string): Record<string, string> {
  const { name, ext, dir } = parse(sourceFilePath)
  const snapshoptFileName = `${name}.snapshot${ext}`
  const snapshoptFilePath = join(dir, snapshoptFileName)
  const source = readFileSync(sourceFilePath, 'utf8')
  return {
    sourceDir: dir,
    sourceFileName: `${name}${ext}`,
    sourceFilePath,
    sourceBaseFileName: name,
    snapshoptFileName,
    snapshoptFilePath,
    source,
  }
}

function success(log: string, globalStartOverride?: number) {
  console.log(`${log} in ${pc.magenta(`${now(globalStartOverride)}ms`)}`)
}

function timed(log: string, globalStartOverride?: number) {
  return `${log} in ${pc.magenta(`${now(globalStartOverride)}ms`)}`
}

function now(globalStartOverride?: number) {
  return (perf.now() - (globalStartOverride ?? start)).toFixed(2)
}
