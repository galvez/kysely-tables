import minimist, { ParsedArgs } from 'minimist'
import { log, confirm, isCancel } from '@clack/prompts'
import pc from 'picocolors'
import { kebabCase } from 'scule'
import { Kysely, KyselyConfig, CompiledQuery } from 'kysely'
import Postgrator from 'postgrator'
import { Pool as PostgresDriver, QueryResult } from 'pg'
import SqliteDriver from 'better-sqlite3'

import { performance as perf } from 'node:perf_hooks'
import {
  existsSync,
  mkdirSync,
  readdirSync,
  readFileSync,
  writeFileSync,
} from 'node:fs'
import { join, parse } from 'node:path'
import {
  createSQLSchemaFromSource,
  createSQLSchemaResetFromSource,
  createSQLSchemaRevision,
} from './index'
import type { DatabaseDriver } from './types'

const start = perf.now()

type CreateDatabaseOptions = {
  driver: DatabaseDriver
  config: KyselyConfig
  name?: string
}

export function createDatabase<Database>({
  driver,
  config,
  name,
}: CreateDatabaseOptions) {
  const argv = minimist(process.argv.slice(1))

  const database = new Kysely<Database>(config)

  if (argv.create) {
    createSchema<Database>(argv, database)
  }

  if (argv.reset) {
    resetSchema<Database>(argv, database)
  }

  if (argv.revision) {
    createSchemaRevision(
      {
        driver,
        config,
        name,
      },
      argv,
      driver,
    )
  }

  return database
}

async function createSchema<Database>(
  argv: ParsedArgs,
  database: Kysely<Database>,
  reset?: boolean,
) {
  const { source, sourceDir, sourceFileName, sourceBaseFileName } = readSource(
    argv._[0],
  )

  const snapshotSchemaFileName = `${sourceBaseFileName}.snapshot.ts`
  const snapshotSchemaFilePath = join(sourceDir, snapshotSchemaFileName)
  if (!reset && existsSync(snapshotSchemaFilePath)) {
    log.warn(
      pc.yellow(
        `${pc.cyan(
          snapshotSchemaFileName,
        )} exists, did you mean to ${pc.magenta('--reset')}?`,
      ),
    )
    console.log()
    process.exit(1)
  }

  const generatedSchema = createSQLSchemaFromSource({
    source,
    fileName: sourceFileName,
  })

  const generatedSchemaFileName = `${sourceBaseFileName}.sql`
  const generatedSchemaFilePath = join(sourceDir, generatedSchemaFileName)
  writeFileSync(generatedSchemaFilePath, generatedSchema.join('\n\n'))
  log.success(timed(`Created ${pc.cyan(generatedSchemaFileName)}`))

  let shouldApply = argv.apply
  if (!shouldApply) {
    const apply = await confirm({
      message: reset ? 'Reset schema?' : 'Apply new schema?',
    })
    if (apply && !isCancel(apply)) {
      shouldApply = true
    }
  }

  if (shouldApply) {
    {
      const start = perf.now()
      await database.transaction().execute(async (trx) => {
        for (const tableSchema of generatedSchema) {
          const query = CompiledQuery.raw(tableSchema)
          await trx.executeQuery(query)
        }
      })
      log.success(timed(`Database updated`, start))
    }

    {
      const start = perf.now()
      writeFileSync(
        snapshotSchemaFilePath, (
          '// This file was autogenerated by kysely-tables as\n' +
          '// a means of diffing against local changes in the main file\n' +
          '// for automatically generating schema revisions (migrations)\n\n' +
          source
        ),
      )
      log.success(timed(`Created ${pc.cyan(snapshotSchemaFileName)}`, start))
    }
  }
  console.log()
}

async function resetSchema<Database>(
  argv: ParsedArgs,
  database: Kysely<Database>,
) {
  const { source, sourceFileName } = readSource(argv._[0])

  await database.transaction().execute(async (trx) => {
    for (const tableSchemaReset of createSQLSchemaResetFromSource({
      source,
      fileName: sourceFileName,
    })) {
      const query = CompiledQuery.raw(tableSchemaReset)
      await trx.executeQuery(query)
    }
  })

  await createSchema(argv, database, true)
}

async function createSchemaRevision(
  options: CreateDatabaseOptions,
  argv: ParsedArgs,
  driver: DatabaseDriver,
) {
  const { source, sourceDir, sourceFileName, sourceBaseFileName } = readSource(
    argv._[0],
  )

  const snapshotFileName = `${sourceBaseFileName}.snapshot.ts`
  const snapshotFilePath = join(sourceDir, snapshotFileName)
  if (!existsSync(snapshotFilePath)) {
    log.warn(
      pc.yellow(
        `${pc.cyan(snapshotFileName)} doesn't exist, ${pc.magenta(
          '--create',
        )} or ${pc.magenta('--reset')} your database first.`,
      ),
    )
    console.log()
    process.exit(1)
  }

  const snapshotSource = readFileSync(snapshotFilePath, 'utf8')
  const revision = createSQLSchemaRevision({
    source,
    snapshotSource,
    snapshotFileName,
    fileName: sourceFileName,
  })

  if (!revision.up.length) {
    log.warn(`No changes detected.`)
    process.exit()
  }

  for (const rev of revision.up) {
    log.info(rev)
  }

  writeRevision(sourceDir, argv.revision, revision.up, revision.down)

  let shouldApply = argv.apply
  if (!shouldApply) {
    const apply = await confirm({
      message: 'Apply schema revision?',
    })
    if (apply && !isCancel(apply)) {
      shouldApply = true
    }
  }

  if (shouldApply) {
    const client = await getPostgratorClient(driver)

    if (client) {
      const postgrator = new Postgrator({
        migrationPattern: join(sourceDir, 'revisions'),
        driver: client.driver as 'pg' | 'sqlite3',
        ...(client.driver === 'sqlite3' && {
          betterSqlite3: true,
        }),
        database: options.name,
        schemaTable: 'schemaversion',
        execQuery: client.execQuery,
      })
      await postgrator.migrate()
      log.success(timed(`Database updated`, perf.now()))
      process.exit()
    } else {
      log.error('An error occured connection to the database.')
      console.log()
      process.exit(1)
    }
  }
}

function readSource(sourceFilePath: string): Record<string, string> {
  const { name, ext, dir } = parse(sourceFilePath)
  const snapshoptFileName = `${name}.snapshot${ext}`
  const snapshoptFilePath = join(dir, snapshoptFileName)
  const source = readFileSync(sourceFilePath, 'utf8')
  return {
    sourceDir: dir,
    sourceFileName: `${name}${ext}`,
    sourceFilePath,
    sourceBaseFileName: name,
    snapshoptFileName,
    snapshoptFilePath,
    source,
  }
}

function writeRevision(
  sourceDir: string,
  name: string,
  up: string[],
  down: string[],
) {
  const revisionsDir = join(sourceDir, 'revisions')
  if (!existsSync(revisionsDir)) {
    const start = perf.now()
    mkdirSync(revisionsDir, { recursive: true })
    log.warn(
      timed(
        `Created ${pc.cyan('revisions')} directory, add it to source control.`,
        start,
      ),
    )
  }
  const revisions = [
    ...new Set(
      readdirSync(revisionsDir)
        .filter((_) => _.match(/\d\d\d\.do/))
        .map((_) => _.slice(0, 3)),
    ),
  ].sort()
  const nextRevision = String(
    revisions.length ? parseInt(revisions.at(-1)!) : '001',
  ).padStart(3, '0')

  const revisionName = kebabCase(name.replace(/\s+/, '-'))
  const doRevisionFileName = `${nextRevision}.do.${revisionName}.sql`
  const undoRevisionFileName = `${nextRevision}.undo.${revisionName}.sql`

  {
    const start = perf.now()
    writeFileSync(join(revisionsDir, doRevisionFileName), up.join('\n\n'))
    log.success(
      timed(`Created ${pc.cyan(`revisions/${doRevisionFileName}`)}`, start),
    )
  }

  {
    const start = perf.now()
    writeFileSync(join(revisionsDir, undoRevisionFileName), down.join('\n\n'))
    log.success(
      timed(`Created ${pc.cyan(`revisions/${undoRevisionFileName}`)}`, start),
    )
  }
}

async function getPostgratorClient(driver: DatabaseDriver): Promise<
  | {
      driver: string
      execQuery: (query: string) => Promise<QueryResult> | { rows: unknown[] }
    }
  | undefined
> {
  if (driver instanceof PostgresDriver) {
    const client = await driver.connect()
    if (client) {
      return {
        driver: 'pg',
        execQuery(query: string) {
          return driver.query(query)
        },
      }
    }
  } else if (driver instanceof SqliteDriver) {
    return {
      driver: 'sqlite3',
      execQuery(query: string) {
        try {
          return {
            rows: driver.prepare(query).all(),
          }
        } catch (err) {
          console.log(err)
          driver.prepare(query).run()
          return { rows: [] }
        }
      },
    }
  }
}

function timed(log: string, globalStartOverride?: number) {
  return `${log} in ${pc.magenta(`${now(globalStartOverride)}ms`)}`
}

function now(globalStartOverride?: number) {
  return (perf.now() - (globalStartOverride ?? start)).toFixed(2)
}
